{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a1436b-26fe-4f12-bb56-0090ead7a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from agq.metrics import get_rank_error, get_hit_ratio, get_ndcg, get_spearman\n",
    "from constants import DATA_STREAM_FOLDER, RANKING_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764d4988-3073-4567-8615-eb1b72c2d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(**{\n",
    "    'path_to_scenario': '../synthetics/scenarios/scenario_16/',  #change me\n",
    "    'streams_root': 'card_10000_202303010000YY',\n",
    "    'aggregation_level': 'file',\n",
    "    'k': -1\n",
    "})\n",
    "\n",
    "metrics = ['rank_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74cc4e6-1350-4138-b1b3-76354abf8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load params\n",
    "with open(f'{args.path_to_scenario}/params.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "    params.update(vars(args))\n",
    "    args = argparse.Namespace(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243df33-8231-41ac-bd86-79662485548f",
   "metadata": {},
   "source": [
    "### Cardinality 1000 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbb31ef-c56b-4e12-acd8-554f8abad9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 78.83it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 89.98it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 85.73it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 87.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 87.60it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 89.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 85.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PURE    5.189796\n",
      "CDF     3.763265\n",
      "UN-F    2.412245\n",
      "UP-F    2.059184\n",
      "UN-T    2.157143\n",
      "UP-T    2.193878\n",
      "CM      5.400000\n",
      "dtype: float64\n",
      "PURE    0.846607\n",
      "CDF     0.800597\n",
      "UN-F    0.899545\n",
      "UP-F    0.396483\n",
      "UN-T    0.695147\n",
      "UP-T    0.679949\n",
      "CM      1.139012\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# will need to be changed after data is generated\n",
    "stream_roots = ['card_1000_20230302165304'] # from your local filesystem; name depends on when run\n",
    "scenario_paths = ['../synthetics/scenarios/scenario_{}'.format(i) for i in range(7)]  # indices depend on order in which they are run\n",
    "#########\n",
    "\n",
    "\n",
    "res = {} \n",
    "for root in stream_roots:\n",
    "    args.streams_root = root\n",
    "    for met in metrics:\n",
    "        dataframe = defaultdict(list)\n",
    "        for scenario in scenario_paths:\n",
    "            args.path_to_scenario = scenario\n",
    "            for topK in [50]:\n",
    "                streams_filenames = os.listdir(f'.{args.data_folder}{DATA_STREAM_FOLDER}/')\n",
    "                if args.streams_root != '':\n",
    "                    streams_filenames = [e for e in streams_filenames if args.streams_root in e]\n",
    "\n",
    "                streams_filenames = sorted(streams_filenames)\n",
    "\n",
    "                scores = defaultdict(list)\n",
    "                for filename in tqdm(streams_filenames):\n",
    "                    stream_name = filename.split('.csv')[0]\n",
    "                    truth_ranking = pd.read_csv(f'.{args.data_folder}{RANKING_FOLDER}/{filename}')\n",
    "\n",
    "                    filename_scores, counter = defaultdict(list), 0\n",
    "                    estimated_ranking = pd.read_csv(\n",
    "                        f'{args.path_to_scenario}/{stream_name}_ranking_0.csv')\n",
    "\n",
    "                    if topK != -1:\n",
    "                        estimated_ranking = estimated_ranking.iloc[:topK - 1]\n",
    "\n",
    "                    filename_scores['rank_error'].append(\n",
    "                        get_rank_error(truth_ranking=truth_ranking, estimated_ranking=estimated_ranking, weighted=False)\n",
    "                    )\n",
    "                    filename_scores['spearman'].append(\n",
    "                        get_spearman(truth_ranking=truth_ranking, estimated_ranking=estimated_ranking, weighted=False)\n",
    "                    )\n",
    "\n",
    "                    for k, v in filename_scores.items():\n",
    "                        v_array = np.array(v)\n",
    "                        scores[k].append((v_array.mean(), v_array.std()))\n",
    "\n",
    "                dataframe[met].append([mean for mean, std in scores[met]])\n",
    "        res[(root, met)] = dataframe\n",
    "        \n",
    "for s in stream_roots:\n",
    "    for m in metrics:\n",
    "        d = pd.DataFrame(res[(s, m)][m], index  =['UP-F', 'UP-T', 'UN-F','UN-T', 'PURE', 'CDF', \"CM\"] ).transpose().mean(axis=0)\n",
    "        print(d[['PURE', 'CDF', 'UN-F','UP-F',   'UN-T',  'UP-T', \"CM\"]])\n",
    "        d = pd.DataFrame(res[(s, m)][m], index  =['UP-F', 'UP-T', 'UN-F','UN-T', 'PURE', 'CDF', \"CM\"] ).transpose().std(axis=0)\n",
    "        print(d[['PURE', 'CDF', 'UN-F','UP-F',   'UN-T',  'UP-T', \"CM\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfda1bd-5930-4117-91ab-7c0ed629601b",
   "metadata": {},
   "source": [
    "### Cardinality 10,000 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f158acd6-4524-442d-9852-bdca41674de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 62.05it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 54.98it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 58.58it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 55.98it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 57.32it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 57.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PURE    5.483673\n",
      "CDF     5.644898\n",
      "UN-F    4.279592\n",
      "UP-F    3.951020\n",
      "UN-T    3.875510\n",
      "UP-T    4.108163\n",
      "dtype: float64\n",
      "PURE    1.017777\n",
      "CDF     1.495584\n",
      "UN-F    1.498794\n",
      "UP-F    1.606946\n",
      "UN-T    1.100421\n",
      "UP-T    1.217594\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# second table (card 10000) - as before, will need to be changed after data is generated\n",
    "stream_roots = ['card_10000_20230302165328']\n",
    "scenario_paths = ['../synthetics/scenarios/scenario_{}'.format(i) for i in range(6)]  # indices depend on order in which they are run\n",
    "#########\n",
    "\n",
    "\n",
    "res = {} \n",
    "for root in stream_roots:\n",
    "    args.streams_root = root\n",
    "    for met in metrics:\n",
    "        dataframe = defaultdict(list)\n",
    "        for scenario in scenario_paths:\n",
    "            args.path_to_scenario = scenario\n",
    "            for topK in [50]:\n",
    "                streams_filenames = os.listdir(f'.{args.data_folder}{DATA_STREAM_FOLDER}/')\n",
    "                if args.streams_root != '':\n",
    "                    streams_filenames = [e for e in streams_filenames if args.streams_root in e]\n",
    "\n",
    "                streams_filenames = sorted(streams_filenames)\n",
    "\n",
    "                scores = defaultdict(list)\n",
    "                for filename in tqdm(streams_filenames):\n",
    "                    stream_name = filename.split('.csv')[0]\n",
    "                    truth_ranking = pd.read_csv(f'.{args.data_folder}{RANKING_FOLDER}/{filename}')\n",
    "\n",
    "                    filename_scores, counter = defaultdict(list), 0\n",
    "                    estimated_ranking = pd.read_csv(\n",
    "                        f'{args.path_to_scenario}/{stream_name}_ranking_0.csv')\n",
    "\n",
    "                    if topK != -1:\n",
    "                        estimated_ranking = estimated_ranking.iloc[:topK - 1]\n",
    "\n",
    "                    filename_scores['rank_error'].append(\n",
    "                        get_rank_error(truth_ranking=truth_ranking, estimated_ranking=estimated_ranking, weighted=False)\n",
    "                    )\n",
    "                    filename_scores['spearman'].append(\n",
    "                        get_spearman(truth_ranking=truth_ranking, estimated_ranking=estimated_ranking, weighted=False)\n",
    "                    )\n",
    "\n",
    "                    for k, v in filename_scores.items():\n",
    "                        v_array = np.array(v)\n",
    "                        scores[k].append((v_array.mean(), v_array.std()))\n",
    "\n",
    "                dataframe[met].append([mean for mean, std in scores[met]])\n",
    "        res[(root, met)] = dataframe\n",
    "        \n",
    "for s in stream_roots:\n",
    "    for m in metrics:\n",
    "        d = pd.DataFrame(res[(s, m)][m], index  =['UP-F', 'UP-T', 'UN-F','UN-T', 'PURE', 'CDF'] ).transpose().mean(axis=0)\n",
    "        print(d[['PURE', 'CDF', 'UN-F','UP-F',   'UN-T',  'UP-T']])#.to_latex())\n",
    "        d = pd.DataFrame(res[(s, m)][m], index  =['UP-F', 'UP-T', 'UN-F','UN-T', 'PURE', 'CDF'] ).transpose().std(axis=0)\n",
    "        print(d[['PURE', 'CDF', 'UN-F','UP-F',   'UN-T',  'UP-T']])#.to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b0278-7ebb-44cd-95de-1da400945c04",
   "metadata": {},
   "source": [
    "### Merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9260b3f-6398-41a4-8f37-0af009f2aefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 74.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGE    1.655102\n",
      "dtype: float64\n",
      "MERGE    0.222408\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#  MERGE RESULTS - scale:100 - as before, will need to be changed after data is generated\n",
    "stream_roots= ['card_1000_20230627145025']\n",
    "scenario_paths = ['../synthetics/scenarios/scenario_18']\n",
    "#########\n",
    "\n",
    "\n",
    "res = {} \n",
    "for root in stream_roots:\n",
    "    args.streams_root = root\n",
    "    for met in metrics:\n",
    "        dataframe = defaultdict(list)\n",
    "        for scenario in scenario_paths:\n",
    "            args.path_to_scenario = scenario\n",
    "            for topK in [50]:\n",
    "                streams_filenames = os.listdir(f'.{args.data_folder}{DATA_STREAM_FOLDER}/')\n",
    "                if args.streams_root != '':\n",
    "                    streams_filenames = [e for e in streams_filenames if args.streams_root in e]\n",
    "\n",
    "                streams_filenames = sorted(streams_filenames)\n",
    "\n",
    "                scores = defaultdict(list)\n",
    "                for filename in tqdm(streams_filenames):\n",
    "                    stream_name = filename.split('.csv')[0]\n",
    "                    truth_ranking = pd.read_csv(f'.{args.data_folder}{RANKING_FOLDER}/{filename}')\n",
    "\n",
    "                    filename_scores, counter = defaultdict(list), 0\n",
    "                    estimated_ranking = pd.read_csv(\n",
    "                        f'{args.path_to_scenario}/{stream_name}_ranking_0.csv')\n",
    "\n",
    "                    if topK != -1:\n",
    "                        estimated_ranking = estimated_ranking.iloc[:topK - 1]\n",
    "\n",
    "                    filename_scores['rank_error'].append(\n",
    "                        get_rank_error(truth_ranking=truth_ranking, estimated_ranking=estimated_ranking, weighted=False)\n",
    "                    )\n",
    "                    filename_scores['spearman'].append(\n",
    "                        get_spearman(truth_ranking=truth_ranking, estimated_ranking=estimated_ranking, weighted=False)\n",
    "                    )\n",
    "\n",
    "                    for k, v in filename_scores.items():\n",
    "                        v_array = np.array(v)\n",
    "                        scores[k].append((v_array.mean(), v_array.std()))\n",
    "\n",
    "                dataframe[met].append([mean for mean, std in scores[met]])\n",
    "        res[(root, met)] = dataframe\n",
    "        \n",
    "for s in stream_roots:\n",
    "    for m in metrics:\n",
    "        d = pd.DataFrame(res[(s, m)][m], index  =['MERGE'] ).transpose().mean(axis=0)\n",
    "        print(d[['MERGE']])\n",
    "        d = pd.DataFrame(res[(s, m)][m], index  =['MERGE'] ).transpose().std(axis=0)\n",
    "        print(d[['MERGE']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5880992-fe93-4ea3-b0ee-68c15ccfc920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syn",
   "language": "python",
   "name": "syn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
